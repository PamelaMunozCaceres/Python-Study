{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hace tan popular a XGBoost es la velocidad y los resultados que logra alcanzar. El algoritmos es paralelizable y por ende logra ser rápido de entrenar, se puede paralelizar en la GPU y entre una red de computadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost ha logrado una performance al nivel del estado del arte en muchas tareas de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el dataset de cancer de mamas (de ML con árboles de decisión) para crear un modelo de XGBoost rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# Traemos los datos\n",
    "wbc = pd.read_csv(\"datasets/MLTreeModels/wbc.csv\")\n",
    "# Reemplazamos por 1 y 0\n",
    "wbc['diagnosis'] = wbc['diagnosis'].replace(['M', 'B'], [1, 0])\n",
    "X = wbc[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "         'area_mean', 'smoothness_mean', 'compactness_mean',\n",
    "         'concavity_mean', 'concave points_mean', 'symmetry_mean',\n",
    "         'fractal_dimension_mean', 'radius_se', 'texture_se',\n",
    "         'perimeter_se', 'area_se', 'smoothness_se',\n",
    "         'compactness_se', 'concavity_se', 'concave points_se',\n",
    "         'symmetry_se', 'fractal_dimension_se', 'radius_worst',\n",
    "         'texture_worst', 'perimeter_worst', 'area_worst',\n",
    "         'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
    "         'concave points_worst', 'symmetry_worst',\n",
    "         'fractal_dimension_worst']]\n",
    "y = wbc[[\"diagnosis\"]]\n",
    "\n",
    "# Dividimos los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                   random_state=123)\n",
    "\n",
    "# Instanciamos el objeto\n",
    "xg_cl = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                          n_estimators=10, seed=123)\n",
    "\n",
    "# Ajustamos a los datos de entrenamiento\n",
    "xg_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos\n",
    "preds = xg_cl.predict(X_test)\n",
    "\n",
    "# Evaluamos\n",
    "score = accuracy_score(y_test, preds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost es un ensamble algorithm ya que usa el resultado de muchos otros modelos para poder predecir. Usa los árboles de decisión como base learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting se puede entender como un concepto que se aplica a un set de modelos de machine learning, es un algoritmo de ensamble. Se usa para converit un conjunto de weak learners en un strong learner (cualquier algoritmo que pueda ser perfeccionado para lograr una mejor performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation en XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar cross-validation directamente con xgboost debemos transformar la data en un formato especifico llamado DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9525\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Traemos los datos\n",
    "wbc = pd.read_csv(\"datasets/MLTreeModels/wbc.csv\")\n",
    "# Reemplazamos por 1 y 0\n",
    "wbc['diagnosis'] = wbc['diagnosis'].replace(['M', 'B'], [1, 0])\n",
    "X = wbc[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "         'area_mean', 'smoothness_mean', 'compactness_mean',\n",
    "         'concavity_mean', 'concave points_mean', 'symmetry_mean',\n",
    "         'fractal_dimension_mean', 'radius_se', 'texture_se',\n",
    "         'perimeter_se', 'area_se', 'smoothness_se',\n",
    "         'compactness_se', 'concavity_se', 'concave points_se',\n",
    "         'symmetry_se', 'fractal_dimension_se', 'radius_worst',\n",
    "         'texture_worst', 'perimeter_worst', 'area_worst',\n",
    "         'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
    "         'concave points_worst', 'symmetry_worst',\n",
    "         'fractal_dimension_worst']]\n",
    "y = wbc[[\"diagnosis\"]]\n",
    "churn_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "params = {\"objective\": \"binary:logistic\", \"max_depth\":4}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=4,\n",
    "                    num_boost_round=10, metrics=\"error\", as_pandas=True)\n",
    "\n",
    "performance = round((1 - cv_results[\"test-error-mean\"]).iloc[-1], 4)\n",
    "print(f\"Accuracy: {performance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
